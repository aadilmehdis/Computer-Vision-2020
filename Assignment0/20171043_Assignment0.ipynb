{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from opencv-python)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pytz in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages (from matplotlib)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /home/aadilmehdis/anaconda3/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting glob\n",
      "\u001b[31m  Could not find a version that satisfies the requirement glob (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for glob\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "\n",
    "# Chroma Key Threshold for Video 1\n",
    "lower_green = np.array([10, 110, 10])\n",
    "upper_green = np.array([90, 190, 90])\n",
    "\n",
    "# Chroma Key Threshold for Video 2\n",
    "lower_white = np.array([210, 210, 210])\n",
    "upper_white = np.array([255, 255, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Output Directories\n",
    "# if not os.path.exists('output'):\n",
    "shutil.rmtree('./output') \n",
    "os.makedirs('output')\n",
    "os.makedirs('output/task_1')\n",
    "os.makedirs('output/task_1/a')\n",
    "os.makedirs('output/task_1/b')\n",
    "os.makedirs('output/task_2')\n",
    "os.makedirs('output/task_3')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to read image\n",
    "def read_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to extract out mask for Chroma Key\n",
    "def extract_mask(img, low_thresh, high_thresh):\n",
    "    mask = cv2.inRange(img, low_thresh, high_thresh)\n",
    "    masked_img = np.copy(img)\n",
    "    masked_img[mask != 0] = [0, 0, 0]\n",
    "    return masked_img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to cut foreground mask shape in the background video\n",
    "def mask_background(bg_img, mask):\n",
    "    bg_img[mask == 0] = [0, 0, 0]\n",
    "    return bg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to merge foreground and background after Chroma Keying\n",
    "def merge_bg_fg(fg, bg):\n",
    "    final_img = fg + bg\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to process a video and apply Chroma Keying\n",
    "def apply_chroma_key(fg_path, bg_path, lower_thresh, upper_thresh):\n",
    "    cap_fg = cv2.VideoCapture(fg_path)\n",
    "    cap_bg = cv2.VideoCapture(bg_path)\n",
    "\n",
    "    if cap_fg.isOpened() == False:\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    if cap_bg.isOpened() == False:\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while cap_fg.isOpened() and cap_bg.isOpened():\n",
    "        ret_fg, fg = cap_fg.read()\n",
    "        ret_bg, bg = cap_bg.read()\n",
    "\n",
    "        if ret_fg == True and ret_bg == True:\n",
    "\n",
    "            masked_img, mask = extract_mask(fg, lower_thresh, upper_thresh)\n",
    "            masked_bg = mask_background(bg, mask)\n",
    "            final_img = merge_bg_fg(masked_img, masked_bg)\n",
    "            frames.append(final_img)\n",
    "\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cap_fg.release()\n",
    "    cap_bg.release()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to combine frames into video\n",
    "def convert_frames_to_video(frames, output_file, fps): \n",
    "    size =  frames[0].shape\n",
    "    size = (size[1], size[0])\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frames)):\n",
    "        out.write(frames[i])\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert a video into images\n",
    "def convert_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if cap.isOpened() == False:\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            frames.append(frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    return frames    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def web_cam_feed(path_to_save):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    i=0\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.imshow('Video Camera Feed'.format(i), frame)\n",
    "            cv2.imwrite(filename=path_to_save+'{}.jpg'.format(i), img=frame)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break \n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Video <-> Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.a - Convert Video to Constituent Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved in ./output/task_1/a\n"
     ]
    }
   ],
   "source": [
    "def task_1_a():\n",
    "    frames = convert_video_frames('./resources/sample_video.mp4')\n",
    "    \n",
    "    i=1\n",
    "    for frame in frames:\n",
    "        cv2.imwrite(\"./output/task_1/a/{}.png\".format(i), frame) \n",
    "        i+=1\n",
    "        \n",
    "    print(\"Output saved in ./output/task_1/a\")\n",
    "    \n",
    "task_1_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.b - Convert Frames to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./output/task_1/a/1.png', './output/task_1/a/2.png', './output/task_1/a/3.png', './output/task_1/a/4.png', './output/task_1/a/5.png', './output/task_1/a/6.png', './output/task_1/a/7.png', './output/task_1/a/8.png', './output/task_1/a/9.png', './output/task_1/a/10.png', './output/task_1/a/11.png', './output/task_1/a/12.png', './output/task_1/a/13.png', './output/task_1/a/14.png', './output/task_1/a/15.png', './output/task_1/a/16.png', './output/task_1/a/17.png', './output/task_1/a/18.png', './output/task_1/a/19.png', './output/task_1/a/20.png', './output/task_1/a/21.png', './output/task_1/a/22.png', './output/task_1/a/23.png', './output/task_1/a/24.png', './output/task_1/a/25.png', './output/task_1/a/26.png', './output/task_1/a/27.png', './output/task_1/a/28.png', './output/task_1/a/29.png', './output/task_1/a/30.png', './output/task_1/a/31.png', './output/task_1/a/32.png', './output/task_1/a/33.png', './output/task_1/a/34.png', './output/task_1/a/35.png', './output/task_1/a/36.png', './output/task_1/a/37.png', './output/task_1/a/38.png', './output/task_1/a/39.png', './output/task_1/a/40.png', './output/task_1/a/41.png', './output/task_1/a/42.png', './output/task_1/a/43.png', './output/task_1/a/44.png', './output/task_1/a/45.png', './output/task_1/a/46.png', './output/task_1/a/47.png', './output/task_1/a/48.png', './output/task_1/a/49.png', './output/task_1/a/50.png', './output/task_1/a/51.png', './output/task_1/a/52.png', './output/task_1/a/53.png', './output/task_1/a/54.png', './output/task_1/a/55.png', './output/task_1/a/56.png', './output/task_1/a/57.png', './output/task_1/a/58.png', './output/task_1/a/59.png', './output/task_1/a/60.png', './output/task_1/a/61.png', './output/task_1/a/62.png', './output/task_1/a/63.png', './output/task_1/a/64.png', './output/task_1/a/65.png', './output/task_1/a/66.png', './output/task_1/a/67.png', './output/task_1/a/68.png', './output/task_1/a/69.png', './output/task_1/a/70.png', './output/task_1/a/71.png', './output/task_1/a/72.png', './output/task_1/a/73.png', './output/task_1/a/74.png', './output/task_1/a/75.png', './output/task_1/a/76.png', './output/task_1/a/77.png', './output/task_1/a/78.png', './output/task_1/a/79.png', './output/task_1/a/80.png', './output/task_1/a/81.png', './output/task_1/a/82.png', './output/task_1/a/83.png', './output/task_1/a/84.png', './output/task_1/a/85.png', './output/task_1/a/86.png', './output/task_1/a/87.png', './output/task_1/a/88.png', './output/task_1/a/89.png', './output/task_1/a/90.png', './output/task_1/a/91.png', './output/task_1/a/92.png', './output/task_1/a/93.png', './output/task_1/a/94.png', './output/task_1/a/95.png', './output/task_1/a/96.png']\n",
      "Output saved in ./output/task_1/b/combined.mp4\n"
     ]
    }
   ],
   "source": [
    "def task_1_b():\n",
    "    files = sort_nicely(glob.glob( \"./output/task_1/a/*.png\"))\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        frames.append(cv2.imread(file))\n",
    "    convert_frames_to_video(frames, \"./output/task_1/b/combined.mp4\", 24)\n",
    "    \n",
    "    print(\"Output saved in ./output/task_1/b/combined.mp4\")\n",
    "    \n",
    "task_1_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Take input from camera and save the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Q to quit the camera feed\n",
      "Output saved in ./output/task_2/\n"
     ]
    }
   ],
   "source": [
    "print(\"Press Q to quit the camera feed\")\n",
    "\n",
    "def task_2():\n",
    "    web_cam_feed('./output/task_2/')\n",
    "    print(\"Output saved in ./output/task_2/\")\n",
    "\n",
    "task_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Apply Chroma Key to a sample video and a custom video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.a - Sample Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_3_a():\n",
    "    frames = apply_chroma_key('./resources/sample_fg.mp4', './resources/sample_bg.mp4', lower_green, upper_green)\n",
    "    convert_frames_to_video(frames, './output/task_3/sample_final.mp4', 24) \n",
    "\n",
    "task_3_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.b - Custom Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_3_b():\n",
    "    frames = apply_chroma_key('./resources/custom_fg.mp4', './resources/custom_bg.mp4', lower_white, upper_white)\n",
    "    convert_frames_to_video(frames, './output/task_3/custom_final.mp4', 24) \n",
    "    \n",
    "task_3_b()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
